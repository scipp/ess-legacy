{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipp as sc\n",
    "import numpy as np\n",
    "import dataconfig # run make_config.py to create this"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some helpers which still need to be added to scipp, ignore this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def midpoints(var, dim):\n",
    "    return 0.5 * (var[dim, 1:] + var[dim, :-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_bin_centers(d, dim):\n",
    "    edges = d.coords[dim].copy()\n",
    "    del d.coords[dim]\n",
    "    d.coords[dim] = 0.5 * (edges[dim, 1:] + edges[dim, :-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_bin_edges(d, dim):\n",
    "    centers = d.coords[dim].copy()\n",
    "    del d.coords[dim]\n",
    "    first = 1.5*centers[dim, 0] - 0.5*centers[dim, 1]\n",
    "    last = 1.5*centers[dim, -1] - 0.5*centers[dim, -2]\n",
    "    bulk = 0.5 * (centers[dim, 1:] + centers[dim, :-1])\n",
    "    edges = sc.concatenate(first, bulk, dim)\n",
    "    edges = sc.concatenate(edges, last, dim)\n",
    "    d.coords[dim] = edges"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def map_to_bins(data, dim, edges):\n",
    "    data = data.copy()\n",
    "    to_bin_edges(data, dim)\n",
    "    bin_width = data.coords[dim][dim,1:] - data.coords[dim][dim,:-1]\n",
    "    bin_width.unit = sc.units.one\n",
    "    data *= bin_width\n",
    "    data = sc.rebin(data, dim, edges)\n",
    "    bin_width = edges[dim,1:] - edges[dim,:-1]\n",
    "    bin_width.unit = sc.units.one\n",
    "    data /= bin_width\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def apply_masks(data):\n",
    "    tof = data.coords['tof']\n",
    "    data.masks['bins'] = sc.less(tof['tof',1:], 1500.0 * sc.units.us) | \\\n",
    "                         (sc.greater(tof['tof',:-1], 17500.0 * sc.units.us) & \\\n",
    "                          sc.less(tof['tof',1:], 19000.0 * sc.units.us))\n",
    "    pos = sc.neutron.position(data)\n",
    "    x = sc.geometry.x(pos)\n",
    "    y = sc.geometry.y(pos)\n",
    "    data.masks['beam-stop'] = sc.less(sc.sqrt(x*x+y*y), 0.045 * sc.units.m)\n",
    "    data.masks['tube-ends'] = sc.greater(sc.abs(x), 0.36 * sc.units.m) # roughly all det IDs listed in original\n",
    "    #MaskDetectorsInShape(Workspace=maskWs, ShapeXML=self.maskingPlaneXML) # irrelevant tiny wedge?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def background_mean(data, dim, begin, end):\n",
    "    coord = data.coords[dim]\n",
    "    assert (coord.unit == begin.unit) and (coord.unit == end.unit)\n",
    "    i = np.searchsorted(coord, begin.value)\n",
    "    j = np.searchsorted(coord, end.value) + 1\n",
    "    return data - sc.mean(data[dim, i:j], dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transmission_fraction(incident_beam, transmission):\n",
    "    # Approximation based on equations in CalculateTransmission documentation\n",
    "    # TODO proper implementation of mantid.CalculateTransmission\n",
    "    return (transmission / transmission) * (incident_beam / incident_beam)\n",
    "    #CalculateTransmission(SampleRunWorkspace=transWsTmp,\n",
    "    #                      DirectRunWorkspace=transWsTmp,\n",
    "    #                      OutputWorkspace=outWsName,\n",
    "    #                      IncidentBeamMonitor=1,\n",
    "    #                      TransmissionMonitor=4, RebinParams='0.9,-0.025,13.5',\n",
    "    #                      FitMethod='Polynomial',\n",
    "    #                      PolynomialOrder=3, OutputUnfittedData=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_monitor_background(data, begin, end):\n",
    "    background = background_mean(data, 'tof', begin, end)\n",
    "    del background.coords['sample-position'] # ensure unit conversion treats this a monitor\n",
    "    background = sc.neutron.convert(background, 'tof', 'wavelength')\n",
    "    background = sc.rebin(background, 'wavelength', wavelength_bins)\n",
    "    return background\n",
    "\n",
    "def setup_transmission(data):\n",
    "    incident_beam = extract_monitor_background(data['spectrum', 0], 40000.0*sc.units.us, 99000.0*sc.units.us)\n",
    "    transmission = extract_monitor_background(data['spectrum', 3], 88000.0*sc.units.us, 98000.0*sc.units.us)\n",
    "    return transmission_fraction(incident_beam, transmission)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def solid_angle(data):\n",
    "    # TODO proper solid angle\n",
    "    # [0.0117188,0.0075,0.0075] bounding box size\n",
    "    pixel_size = 0.0075 * sc.units.m \n",
    "    pixel_length = 0.0117188 * sc.units.m\n",
    "    L2 = sc.neutron.l2(data)\n",
    "    return (pixel_size * pixel_length) / (L2 * L2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_direct_beam(filenames, layers=None):\n",
    "    \"\"\"\n",
    "    Load one or multiple direct beam files.\n",
    "    \n",
    "    If there are multiple files they are concatenated along a dim named 'layer'\n",
    "    \"\"\"\n",
    "    if isinstance(filenames, str):\n",
    "        filenames = [filenames]\n",
    "    dbs = [ load_rkh(filename=f'{path}/{name}') for name in filenames ]\n",
    "    if len(dbs) == 1:\n",
    "        return dbs[0]\n",
    "    direct_beam = None\n",
    "    for db in dbs:\n",
    "        if direct_beam is None:\n",
    "            direct_beam = db\n",
    "        else:\n",
    "            direct_beam = sc.concatenate(direct_beam, db, 'layer')\n",
    "    direct_beam.coords['layer'] = sc.Variable(dims=['layer'], dtype=sc.dtype.int32, values=np.arange(len(dbs)))\n",
    "    return direct_beam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_wavelength(data, transmission, direct_beam):\n",
    "    transmission = setup_transmission(transmission)\n",
    "    data = data.copy()\n",
    "    apply_masks(data)\n",
    "    data = sc.neutron.convert(data, 'tof', 'wavelength', out=data)\n",
    "    data = sc.rebin(data, 'wavelength', wavelength_bins)\n",
    "\n",
    "    monitor = data.attrs['monitor1'].value\n",
    "    monitor = background_mean(monitor, 'tof', 40000.0*sc.units.us, 99000.0*sc.units.us)\n",
    "    monitor = sc.neutron.convert(monitor, 'tof', 'wavelength', out=monitor)\n",
    "    monitor = sc.rebin(monitor, 'wavelength', wavelength_bins)\n",
    "\n",
    "    direct_beam = map_to_bins(direct_beam, 'wavelength', monitor.coords['wavelength'])\n",
    "    direct_beam = monitor * transmission * direct_beam\n",
    "    \n",
    "    d = sc.Dataset({'data':data, 'norm':solid_angle(data)*direct_beam})\n",
    "    to_bin_centers(d, 'wavelength')\n",
    "    return d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_slices(var, dim, cutting_points):\n",
    "    points = var.shape[0]\n",
    "    slices = []\n",
    "    for i in range(cutting_points.shape[0]-1):\n",
    "        start = cutting_points[dim, i]\n",
    "        end = cutting_points[dim, i+1]\n",
    "        # scipp treats ranges as closed on left and open on right: [left, right)\n",
    "        first = sc.sum(sc.less(var, start), dim).value\n",
    "        last = points - sc.sum(sc.greater_equal(var, end), dim).value\n",
    "        assert first >= 0\n",
    "        assert last <= points\n",
    "        slices.append(slice(first,last))\n",
    "    return slices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reduce(data, q_bins):\n",
    "    data = sc.histogram(data, q_bins)\n",
    "    if 'layer' in data.coords:\n",
    "        return sc.groupby(data, 'layer').sum('spectrum')\n",
    "    else:\n",
    "        return sc.sum(data, 'spectrum')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reduce_by_wavelength(data, q_bins, wavelength_bands):\n",
    "    slices = make_slices(midpoints(data.coords['wavelength'], 'wavelength'), 'wavelength', wavelength_bands)\n",
    "    data = sc.neutron.convert(data, 'wavelength', 'Q', out=data) # TODO no gravity yet\n",
    "    bands = None\n",
    "    for s in slices:\n",
    "        band = sc.histogram(data['Q', s], q_bins)\n",
    "        band = sc.groupby(band, 'layer').sum('spectrum')\n",
    "        bands = sc.concatenate(bands, band, 'wavelength') if bands is not None else band\n",
    "    bands.coords['wavelength'] = wavelength_bands\n",
    "    return bands"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fitting and iteration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def select_bins(array, dim, start, end):\n",
    "    coord = array.coords[dim]\n",
    "    edges = coord.shape[0]\n",
    "    # scipp treats bins as closed on left and open on right: [left, right)\n",
    "    first = sc.sum(sc.less_equal(coord, start), dim).value - 1\n",
    "    last = edges - sc.sum(sc.greater(coord, end), dim).value\n",
    "    assert first >= 0\n",
    "    assert last < edges\n",
    "    return array[dim, first:last+1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def fit_gauss_coil(data):\n",
    "    #sc.to_html(data)\n",
    "    #x = data.coords['Q']\n",
    "    #plot(data)\n",
    "    import sys\n",
    "    sys.path.append('/home/simon/mantid/LOKI/DirectBeamiterationData')\n",
    "    import gauss_coil_fit1\n",
    "\n",
    "    from scipp.compat.mantid import fit\n",
    "    model = \"polyGaussCoil\"\n",
    "    params = \"I0=60.0,Rg=50.0,Mw_by_Mn=1.02,Background=0.25\"\n",
    "    ties = \"Rg=50.0,Mw_by_Mn=1.02\"\n",
    "\n",
    "    # multiple 1D fits, could make a more convenient wrapper\n",
    "    I0 = sc.Variable(dims=['layer'], shape=[n_layer], dtype=sc.dtype.float64, variances=True)\n",
    "    for i in range(data.coords['layer'].shape[0]):\n",
    "        fit_result, fitted = fit(data['layer',i], mantid_args={\n",
    "            'Function':f\"name={model},{params}\",\n",
    "            'Ties':ties})\n",
    "        I0['layer', i] = fit_result['parameter', 0].data\n",
    "        #sc.to_html(fit_result)\n",
    "        #from scipp.plot import plot\n",
    "        #plot(fitted)\n",
    "    return I0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = dataconfig.data_root\n",
    "direct_beam_file = 'DirectBeam_20feb_full_v3.dat'\n",
    "moderator_file = 'ModeratorStdDev_TS2_SANS_LETexptl_07Aug2015.txt'\n",
    "sample_run_number = 49338\n",
    "sample_transmission_run_number = 49339\n",
    "background_run_number = 49334\n",
    "background_transmission_run_number = 49335\n",
    "\n",
    "def load_larmor(run_number):\n",
    "    return sc.neutron.load(filename=f'{path}/LARMOR000{run_number}.nxs')\n",
    "\n",
    "def load_rkh(filename):\n",
    "    return sc.neutron.load(\n",
    "           filename=filename,\n",
    "           mantid_alg='LoadRKH',\n",
    "           mantid_args={'FirstColumnValue':'Wavelength'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "sample_trans = load_larmor(sample_transmission_run_number)\n",
    "sample = load_larmor(sample_run_number)\n",
    "background_trans = load_larmor(background_transmission_run_number)\n",
    "background = load_larmor(background_run_number)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "dtype = sample.coords['position'].dtype\n",
    "sample_pos_offset = sc.Variable(value=[0.0, 0.0, 0.30530], unit=sc.units.m, dtype=dtype)\n",
    "bench_pos_offset = sc.Variable(value=[0.0, 0.001, 0.0], unit=sc.units.m, dtype=dtype)\n",
    "for item in [sample, sample_trans, background, background_trans]:\n",
    "    item.coords['sample-position'] += sample_pos_offset\n",
    "    item.coords['position'] += bench_pos_offset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "wavelength_bins = sc.Variable(\n",
    "    dims=['wavelength'],\n",
    "    unit=sc.units.angstrom,\n",
    "    values=np.geomspace(0.9, 13.5, num=110))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "q_bins = sc.Variable(\n",
    "    dims=['Q'],\n",
    "    unit=sc.units.one/sc.units.angstrom,\n",
    "    values=np.geomspace(0.007999, 0.6, num=55))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wavelength_bins = sc.Variable(\n",
    "    dims=['wavelength'],\n",
    "    unit=sc.units.angstrom,\n",
    "    values=np.geomspace(1.0, 12.9, num=110))\n",
    "wavelength_bands = sc.Variable(\n",
    "    dims=['wavelength'],\n",
    "    unit=sc.units.angstrom,\n",
    "    values=[1.0,1.4,1.8,2.2,3.0,4.0,5.0,7.0,9.0,11.0,12.9])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "I0_expected = 55.77 * sc.units.one"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ratio of reduced_band / reduced is averaged (integrated) over wavelength-dependent interval\n",
    "# Use a mask, so we can just use `sc.mean`.\n",
    "# Note that in the original script Integration(...)/delta_Q is used, but this\n",
    "# is biased due to log binning, maybe on purpose...?\n",
    "#q1longW = 0.008 * (sc.units.one / sc.units.angstrom)\n",
    "#q2longW = 0.05 * (sc.units.one / sc.units.angstrom)\n",
    "#q1shortW = 0.1 * (sc.units.one / sc.units.angstrom)\n",
    "#q2shortW = 0.22 * (sc.units.one / sc.units.angstrom)\n",
    "qlongW = sc.Variable(dims=['bound'], unit=q_bins.unit, values=[0.008, 0.05])\n",
    "qshortW = sc.Variable(dims=['bound'], unit=q_bins.unit, values=[0.1, 0.22])\n",
    "damp = 1.0*sc.units.one"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_and_subtract(sample, background):\n",
    "    sample_norm = sample['data']/sample['norm']\n",
    "    background_norm = background['data']/background['norm']\n",
    "    return sample_norm - background_norm\n",
    "\n",
    "def q_range_mask(wavelength):\n",
    "    inv_w = sc.reciprocal(wavelength)\n",
    "    dim = inv_w.dims[0]\n",
    "    q_range = qlongW + (\n",
    "        sc.concatenate(inv_w[dim,1:].copy(), inv_w[dim,:-1].copy(), 'bound')\n",
    "        - inv_w[dim,-1])*(qshortW-qlongW)/(inv_w[dim,0]-inv_w[dim,-1])\n",
    "    qmin = q_range['bound',0]\n",
    "    qmax = q_range['bound',1]\n",
    "    return sc.greater(qmin, q_bins['Q',:-1]) | sc.less(qmax, q_bins['Q',1:])\n",
    "\n",
    "def interpolate_cubic_spline(data, x, dim):\n",
    "    from scipy import interpolate\n",
    "    out = None\n",
    "    for i in range(data.coords['layer'].shape[0]):\n",
    "        tck = interpolate.splrep(midpoints(data.coords[dim], dim).values, data['layer',i].values)\n",
    "        # TODO uncertainties\n",
    "        y = sc.Variable(dims=[dim], values=interpolate.splev(x.values, tck))\n",
    "        if out is None:\n",
    "            out = y\n",
    "        else:\n",
    "            out = sc.concatenate(out, y, 'layer')\n",
    "    #from scipp.plot import plot\n",
    "    #plot(data['layer',1])\n",
    "    #x = x.copy()\n",
    "    #plot(sc.DataArray(out['layer',1].copy(), coords={dim:x}))\n",
    "    return out\n",
    "\n",
    "def direct_beam_iteration(direct_beam, layer, flat_background=0.25*sc.units.one):\n",
    "    print('start iteration')\n",
    "    direct_beam_by_pixel = sc.choose(layer, choices=direct_beam, dim='layer')\n",
    "    sample_wavelength = to_wavelength(data=sample, transmission=sample_trans, direct_beam=direct_beam_by_pixel)\n",
    "    background_wavelength = to_wavelength(data=background, transmission=background_trans, direct_beam=direct_beam_by_pixel)\n",
    "\n",
    "    # sum all spectra within a layer with a wavelength band\n",
    "    # TODO make sum over spectra within layer more explicit\n",
    "    sample_q_lambda = reduce_by_wavelength(sample_wavelength, q_bins, wavelength_bands=wavelength_bands)\n",
    "    background_q_lambda = reduce_by_wavelength(background_wavelength, q_bins, wavelength_bands=wavelength_bands)\n",
    "    reduced_by_wavelength = normalize_and_subtract(sample_q_lambda, background_q_lambda)\n",
    "    \n",
    "    # sum wavelength bands to reduce for full range\n",
    "    sample_q1d = sc.sum(sample_q_lambda, 'wavelength')\n",
    "    background_q1d = sc.sum(background_q_lambda, 'wavelength')\n",
    "    reduced = normalize_and_subtract(sample_q1d, background_q1d)\n",
    "    #plot(reduced)\n",
    "    \n",
    "    I0 = fit_gauss_coil(select_bins(reduced, 'Q', qlongW['bound', 0], qshortW['bound', 1]))\n",
    "    #sc.to_html(I0)\n",
    "    scale = I0_expected / I0\n",
    "    #reduced *= scale # TODO why scale if only ratio used?\n",
    "    #reduced_by_wavelength *= scale\n",
    "    direct_beam /= scale\n",
    "    ratio = (reduced_by_wavelength - flat_background) / (reduced - flat_background)\n",
    "\n",
    "    wavelength = reduced_by_wavelength.coords['wavelength']\n",
    "    ratio.masks['Q-range-mask'] = q_range_mask(wavelength)\n",
    "    norm = 1.0*sc.units.one + damp*(sc.mean(ratio, 'Q') - 1.0*sc.units.one)\n",
    "    # TODO original uses scale for interpolation, but is this necessary if we don't deal with histogram?\n",
    "    # d_w = wavelength['wavelength',1:]-wavelength['wavelength',:-1]\n",
    "    # scale = 1.0*sc.units.angstrom + damp*(norm*d_w-1.0*sc.units.angstrom)\n",
    "    direct_beam *= interpolate_cubic_spline(norm, direct_beam.coords['wavelength'], 'wavelength')\n",
    "    return direct_beam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "from loki import LoKI\n",
    "loki = LoKI()\n",
    "layer = loki.layers()\n",
    "n_layer = sc.max(layer).value+1\n",
    "direct_beam = load_direct_beam([direct_beam_file]*n_layer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "direct_beams = sc.Dataset()\n",
    "direct_beams['iteration-0'] = direct_beam\n",
    "iterations = 1\n",
    "for i in range(iterations):\n",
    "    direct_beam = direct_beam_iteration(direct_beam, layer)\n",
    "    direct_beams[f'iteration-{i+1}'] = direct_beam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipp.plot import plot\n",
    "plot(direct_beams['layer',0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xxx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def trapz(data, dim):\n",
    "    coord = data.coords[dim]\n",
    "    height = 0.5 * (data.data[dim,:-1] + data.data[dim,1:])\n",
    "    width = coord[dim,1:] - coord[dim,:-1]\n",
    "    return sc.sum(height * width, dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "direct_beam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "integral = trapz(direct_beam['wavelength', 10:-10], 'wavelength')\n",
    "integral"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wavelength_bins"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "solid_angle(sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "layer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Direct beam\n",
    "Choose one of the following options (run only one of the two cells) to load the direct beam file:\n",
    "### Option 1: Same for all pixels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "direct_beam = load_direct_beam(direct_beam_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Option 2: Different direct beam for different groups of pixels\n",
    "Using randomly assigned IDs for this, change to something appropriate.\n",
    "Filenames should be provided as a list, here we use same for all."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "# TODO replace by indexing scheme\n",
    "# id = pixel + n_pixel * (straw + n_straw * (tube + n_tube * (...)))\n",
    "# use modulo to convert from id to layer?\n",
    "n_layer = 11\n",
    "layer = sc.Variable(dims=['spectrum'],\n",
    "                    values=np.random.randint(low=0,\n",
    "                                             high=n_layer,\n",
    "                                             size=len(sample.coords['spectrum'].values)))\n",
    "\n",
    "direct_beam = load_direct_beam([direct_beam_file]*n_layer)\n",
    "direct_beam = sc.choose(layer, choices=direct_beam, dim='layer')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q1D\n",
    "\n",
    "### Step 1: Convert to Q\n",
    "Note that this is not `I(Q)` yet.\n",
    "Sum over spectra and normalization happens later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "sample_q = to_q(data=sample, transmission=sample_trans, direct_beam=direct_beam)\n",
    "background_q = to_q(data=background, transmission=background_trans, direct_beam=direct_beam)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2: Reduce (sum spectra)\n",
    "Sum spectra. This does take into account potential different layers (see `'layers'` coord).\n",
    "Note that this is still not `I(Q)`, normalization happens later.\n",
    "We have two options, reduce the full wavelength range, or reduce individual wavelength bands."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "q_bins = sc.Variable(\n",
    "    dims=['Q'],\n",
    "    unit=sc.units.one/sc.units.angstrom,\n",
    "    values=np.geomspace(0.008, 0.6, num=55))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "sample_q_all = reduce(sample_q, q_bins)\n",
    "background_q_all = reduce(background_q, q_bins)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "sample_q_lambda = reduce_by_wavelength(sample_q, q_bins, wavelength_bands=8)\n",
    "background_q_lambda = reduce_by_wavelength(background_q, q_bins, wavelength_bands=8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Summing the latter over `'wavelength'` should give an equivalent result to the full wavelength result, but the former is faster if bands are not required."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 3\n",
    "There are multiple options for this step, depending on whether we need to consider wavelength bands and layers (pixel groups) independently or now.\n",
    "\n",
    "#### Option 1: Combine all layers and normalize\n",
    "This gives just a single `I(Q)` and can be compared to the default output from Mantid's `Q1D`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if 'layer' in sample_q_all.dims:\n",
    "    sample_q1d = sc.sum(sample_q_all, 'layer')\n",
    "    background_q1d = sc.sum(background_q_all, 'layer')\n",
    "else:\n",
    "    sample_q1d = sample_q_all\n",
    "    background_q1d = background_q_all\n",
    "sample_q1d = sample_q1d['data']/sample_q1d['norm']\n",
    "background_q1d = background_q1d['data']/background_q1d['norm']\n",
    "reduced = sample_q1d - background_q1d\n",
    "\n",
    "reduced.attrs['UserFile'] = sc.Variable(\n",
    "    value='USER_Raspino_191E_BCSLarmor_24Feb2020_v1.txt')\n",
    "reduced.attrs['Transmission'] = sc.Variable(\n",
    "    value=f'{sample_transmission_run_number}_trans_sample_0.9_13.5_unfitted')\n",
    "reduced.attrs['TransmissionCan'] = sc.Variable(\n",
    "    value=f'{background_transmission_run_number}_trans_can_0.9_13.5_unfitted')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipp.plot import plot\n",
    "values, stddev = np.loadtxt(\"mantid_reduced.txt\")\n",
    "q = np.loadtxt(\"mantid_reduced_q.txt\")\n",
    "\n",
    "mantid = sc.DataArray(data=sc.Variable(['Q'],\n",
    "                                       values=values,\n",
    "                                       variances=stddev*stddev),\n",
    "                      coords={'Q': sc.Variable(['Q'], unit=sc.units.one/sc.units.angstrom, values=q)})\n",
    "mantid = sc.rebin(mantid, 'Q', reduced.coords['Q'])\n",
    "\n",
    "ds = sc.Dataset({'mantid': mantid, 'scipp': reduced})\n",
    "plot(ds, logy=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Option 2: Normalize without combining layers or wavelengths\n",
    "\n",
    "Note that there are multiple options here: We can sum over `'layer'` or sum over `'wavelength'`, or neither.\n",
    "As usualy, summation would need to be done *before* normalization, see option 1.\n",
    "Here we do not perform any sum and obtain `I(wavelength, layer, Q)`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_q = sample_q_lambda['data']/sample_q_lambda['norm']\n",
    "background_q = background_q_lambda['data']/background_q_lambda['norm']\n",
    "reduced = sample_q - background_q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reduced"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from scipp.plot import plot\n",
    "plot(reduced['layer',0:4], collapse='Q', logy=True)\n",
    "plot(reduced, log=True, vmin=-2, vmax=np.log(3.0)) # TODO fix https://github.com/scipp/scipp/issues/1112"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
